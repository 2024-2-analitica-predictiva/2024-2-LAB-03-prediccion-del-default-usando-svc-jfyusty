{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Importa la biblioteca pandas.\n",
    "\n",
    "# Cargar datos de prueba desde un archivo zip.\n",
    "test_data = pd.read_csv(\n",
    "    \"../files/input/test_data.csv.zip\",  # Especifica la ruta relativa al archivo .zip que contiene los datos de prueba.\n",
    "    index_col=False,  # Indica que no se debe usar ninguna columna como índice del DataFrame.\n",
    "    compression=\"zip\",  # Especifica que el archivo está comprimido como un .zip.\n",
    ")\n",
    "\n",
    "# Cargar datos de entrenamiento desde un archivo zip.\n",
    "train_data = pd.read_csv(\n",
    "    \"../files/input/train_data.csv.zip\",  # Especifica la ruta relativa al archivo .zip que contiene los datos de entrenamiento.\n",
    "    index_col=False,  # Indica que no se debe usar ninguna columna como índice del DataFrame.\n",
    "    compression=\"zip\",  # Especifica que el archivo está comprimido como un .zip.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# limpieza de los datos\n",
    "#\n",
    "\n",
    "import numpy as np # importa la biblioteca numpy\n",
    "\n",
    "# Renombrar la columna 'default payment next month' a 'default'.\n",
    "test_data.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "train_data.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'ID' de ambos DataFrames.\n",
    "test_data.drop(columns='ID', inplace=True)\n",
    "train_data.drop(columns='ID', inplace=True)\n",
    "\n",
    "# Filtrar y eliminar filas donde los registros con informacion no disponible.\n",
    "test_data = test_data[(test_data['EDUCATION'] != 0) & (test_data['MARRIAGE'] != 0)]\n",
    "train_data = train_data[(train_data['EDUCATION'] != 0) & (train_data['MARRIAGE'] != 0)]\n",
    "\n",
    "# Para la columna EDUCATION, valores > 4 indican niveles superiores de educación, agrupe estos valores en la categoría \"others\".\n",
    "test_data['EDUCATION'] = test_data['EDUCATION'].apply(lambda x: 4 if x > 4 else x)\n",
    "train_data['EDUCATION'] = train_data['EDUCATION'].apply(lambda x: 4 if x > 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# separacion de los datos\n",
    "#\n",
    "\n",
    "# Elimina la columna 'default' del DataFrame train_data para crear el conjunto de características de entrenamiento.\n",
    "x_train = train_data.drop(columns=\"default\")\n",
    "\n",
    "# Extrae la columna 'default' de train_data y la usa como el conjunto de etiquetas de entrenamiento.\n",
    "y_train = train_data[\"default\"]\n",
    "\n",
    "# Elimina la columna 'default' del DataFrame test_data para crear el conjunto de características de prueba.\n",
    "x_test = test_data.drop(columns=\"default\")\n",
    "\n",
    "# Extrae la columna 'default' de test_data y la usa como el conjunto de etiquetas de prueba.\n",
    "y_test = test_data[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# eleccion modelo y transformaciones\n",
    "#\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definición de las columnas categóricas y numéricas.\n",
    "categorical_features = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]  # Lista de columnas categóricas.\n",
    "numeric_features = x_train.columns.difference(categorical_features + [\"default\"]).tolist()  # Lista de columnas numéricas.\n",
    "\n",
    "# Configuración del preprocesador.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),  # Codifica variables categóricas.\n",
    "        ('scaler', StandardScaler(), numeric_features)  # Escala las variables numéricas para tener media 0 y desviación estándar 1.\n",
    "    ],\n",
    "    remainder='passthrough'  # Pasa sin cambios las columnas que no están incluidas en 'transformers'.\n",
    ")\n",
    "\n",
    "# Creación del pipeline.\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),  # Aplica las transformaciones del preprocesador.\n",
    "    ('pca', PCA()),  # Aplica PCA para reducir la dimensionalidad.\n",
    "    (\"feature_selection\", SelectKBest(score_func=f_classif)),  # Selecciona las características más relevantes.\n",
    "    (\"classifier\", SVC(kernel=\"rbf\", random_state=0, max_iter=-1))  # Usa un modelo de SVM con kernel RBF.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'classifier__gamma': 0.1, 'feature_selection__k': 12, 'pca__n_components': 20}\n",
      "Mejor precisión balanceada: 0.6500332144162928\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# hiperparametros y ajuste\n",
    "#\n",
    "\n",
    "# Definición de la rejilla de parámetros para la búsqueda.\n",
    "param_grid = {\n",
    "    'pca__n_components': [20, x_train.shape[1]-2],  # Número de componentes principales a mantener.\n",
    "    'feature_selection__k': [12],  # Número de características a seleccionar.\n",
    "    'classifier__gamma': [0.1]  # Parámetro gamma para el kernel RBF.\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV.\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline,  # El pipeline que incluye preprocesamiento, selección de características y clasificador.\n",
    "    param_grid=param_grid,  # La rejilla de hiperparámetros definida arriba.\n",
    "    scoring='balanced_accuracy',  # Usa balanced_accuracy como métrica de evaluación.\n",
    "    cv=10,  # Realiza validación cruzada con 10 particiones.\n",
    "    n_jobs=-1  # Usa todos los núcleos disponibles para procesar las combinaciones en paralelo.\n",
    ")\n",
    "\n",
    "# Ajusta el modelo en el conjunto de entrenamiento.\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor score.\n",
    "print(\"Mejores parámetros:\", model.best_params_)\n",
    "print(\"Mejor precisión balanceada:\", model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejores parámetros: {'classifier__gamma': 0.1, 'classifier__kernel': 'rbf', 'feature_selection__k': 12, 'pca__n_components': 20}\n",
    "\n",
    "Mejor precisión balanceada: 0.6500332144162928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../files/models/model.pkl.gz'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# guardar modelo\n",
    "#\n",
    "\n",
    "import gzip  # Para comprimir y descomprimir archivos.\n",
    "import pickle  # Para serializar y deserializar objetos de Python, como modelos de machine learning.\n",
    "import os  # Para manejo de directorios.\n",
    "\n",
    "models_dir = '../files/models'  # Define la ruta donde se guardarán los modelos.\n",
    "os.makedirs(models_dir, exist_ok=True)  # Crea el directorio si no existe.\n",
    "\n",
    "model_path = \"../files/models/model.pkl.gz\"  # Define la ruta completa para el archivo del modelo.\n",
    "\n",
    "with gzip.open(model_path, \"wb\") as f:  # Abre el archivo en modo escritura binaria ('wb') y comprime el contenido.\n",
    "    pickle.dump(model, f)  # Serializa el objeto del modelo y lo guarda en el archivo comprimido.\n",
    "\n",
    "model_path  # Devuelve la ruta donde se guardó el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# funcion para guardar  metricas en json\n",
    "#\n",
    "\n",
    "import json  # Manejo de archivos JSON.\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score  # Métricas de evaluación.\n",
    "\n",
    "def calculate_and_save_metrics(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)  # Predice etiquetas para el conjunto de entrenamiento.\n",
    "    y_test_pred = model.predict(X_test)  # Predice etiquetas para el conjunto de prueba.\n",
    "\n",
    "    metrics_train = {\n",
    "        'type': 'metrics',  # Tipo de datos guardados.\n",
    "        'dataset': 'train',  # Identifica que las métricas corresponden al conjunto de entrenamiento.\n",
    "        'precision': precision_score(y_train, y_train_pred, zero_division=0),  # Precisión del modelo.\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_train, y_train_pred),  # Exactitud balanceada.\n",
    "        'recall': recall_score(y_train, y_train_pred, zero_division=0),  # Sensibilidad o recall.\n",
    "        'f1_score': f1_score(y_train, y_train_pred, zero_division=0)  # Puntaje F1.\n",
    "    }\n",
    "\n",
    "    metrics_test = {\n",
    "        'type': 'metrics',\n",
    "        'dataset': 'test',  # Identifica que las métricas corresponden al conjunto de prueba.\n",
    "        'precision': precision_score(y_test, y_test_pred, zero_division=0),\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_test, y_test_pred),\n",
    "        'recall': recall_score(y_test, y_test_pred, zero_division=0),\n",
    "        'f1_score': f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    }\n",
    "\n",
    "    output_dir = os.path.abspath('../files/output')  # Define el directorio donde se guardarán los resultados.\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Crea el directorio si no existe.\n",
    "\n",
    "    output_path = os.path.join(output_dir, 'metrics.json')  # Define la ruta completa para el archivo JSON.\n",
    "    with open(output_path, 'w') as f:  # Abre el archivo en modo escritura.\n",
    "        f.write(json.dumps(metrics_train) + '\\n')  # Escribe las métricas del conjunto de entrenamiento en formato JSON.\n",
    "        f.write(json.dumps(metrics_test) + '\\n')  # Escribe las métricas del conjunto de prueba en formato JSON.\n",
    "\n",
    "    return metrics_train, metrics_test # Retornar las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# funcion para guardar matrices de confucion en json\n",
    "#\n",
    "\n",
    "from sklearn.metrics import confusion_matrix  # Importa la función para calcular matrices de confusión.\n",
    "\n",
    "def calculate_and_save_confusion_matrices(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_train_pred = model.predict(X_train)  # Predice etiquetas para el conjunto de entrenamiento.\n",
    "    y_test_pred = model.predict(X_test)  # Predice etiquetas para el conjunto de prueba.\n",
    "\n",
    "    # Calcular matrices de confusión\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)  # Calcula la matriz de confusión para el conjunto de entrenamiento.\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)  # Calcula la matriz de confusión para el conjunto de prueba.\n",
    "\n",
    "    # Convertir las matrices de confusión en formato JSON\n",
    "    def format_confusion_matrix(cm, dataset_type):\n",
    "        return {\n",
    "            'type': 'cm_matrix',  # Tipo de métrica guardada.\n",
    "            'dataset': dataset_type,  # Indica si es entrenamiento o prueba.\n",
    "            'true_0': {  # Valores verdaderos para la clase 0.\n",
    "                'predicted_0': int(cm[0, 0]),  # Predicción correcta para clase 0.\n",
    "                'predicted_1': int(cm[0, 1])   # Predicción incorrecta para clase 0.\n",
    "            },\n",
    "            'true_1': {  # Valores verdaderos para la clase 1.\n",
    "                'predicted_0': int(cm[1, 0]),  # Predicción incorrecta para clase 1.\n",
    "                'predicted_1': int(cm[1, 1])   # Predicción correcta para clase 1.\n",
    "            }\n",
    "        }\n",
    "\n",
    "    metrics = [\n",
    "        format_confusion_matrix(cm_train, 'train'),  # Matriz de confusión para entrenamiento.\n",
    "        format_confusion_matrix(cm_test, 'test')    # Matriz de confusión para prueba.\n",
    "    ]\n",
    "\n",
    "    # Guardar las matrices de confusión en el archivo JSON\n",
    "    output_path = '../files/output/metrics.json'  # Ruta del archivo JSON.\n",
    "    with open(output_path, 'a') as f:  # Abre el archivo en modo agregar ('a').\n",
    "        for metric in metrics:\n",
    "            f.write(json.dumps(metric) + '\\n')  # Convierte el diccionario en JSON y lo guarda.\n",
    "\n",
    "    return cm_train, cm_test # Devuelve las matrices de confusión originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# funcion ejecutura\n",
    "#\n",
    "\n",
    "def main(model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Crear el directorio de salida si no existe\n",
    "    import os\n",
    "    os.makedirs('../files/output', exist_ok=True)\n",
    "\n",
    "    # Calcular y guardar las métricas\n",
    "    metrics_train, metrics_test = calculate_and_save_metrics(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # Imprimir las métricas\n",
    "    print(\"Métricas del conjunto de entrenamiento:\")\n",
    "    for key, value in metrics_train.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    print(\"\\nMétricas del conjunto de prueba:\")\n",
    "    for key, value in metrics_test.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Calcular, guardar e imprimir las matrices de confusión\n",
    "    cm_train, cm_test = calculate_and_save_confusion_matrices(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print(\"\\nMatriz de confusión del conjunto de entrenamiento:\")\n",
    "    print(cm_train)\n",
    "\n",
    "    print(\"\\nMatriz de confusión del conjunto de prueba:\")\n",
    "    print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas del conjunto de entrenamiento:\n",
      "type: metrics\n",
      "dataset: train\n",
      "precision: 0.7026920031670626\n",
      "balanced_accuracy: 0.6646916688511463\n",
      "recall: 0.37566137566137564\n",
      "f1_score: 0.4895876430837126\n",
      "\n",
      "Métricas del conjunto de prueba:\n",
      "type: metrics\n",
      "dataset: test\n",
      "precision: 0.6736745886654479\n",
      "balanced_accuracy: 0.6681000149987337\n",
      "recall: 0.38667366211962223\n",
      "f1_score: 0.49133333333333334\n",
      "\n",
      "Matriz de confusión del conjunto de entrenamiento:\n",
      "[[15477   751]\n",
      " [ 2950  1775]]\n",
      "\n",
      "Matriz de confusión del conjunto de prueba:\n",
      "[[6716  357]\n",
      " [1169  737]]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso:\n",
    "main(model, x_train, x_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
